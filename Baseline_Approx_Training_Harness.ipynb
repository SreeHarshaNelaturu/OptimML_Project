{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-SZkEAVn7p9"
      },
      "source": [
        "\n",
        "Approximate Operations and Baseline Training Harness\n",
        "---\n",
        "\n",
        "Based on operations defined in: https://github.com/adelmanm/approx\n",
        "\n",
        "[Faster Neural Network Training with Approximate Tensor Operations](https://arxiv.org/abs/1805.08079) by Menachem Adelman, Kfir Y. Levy, Ido Hakimi, Mark Silberstein\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJJVGqc8tE3y"
      },
      "outputs": [],
      "source": [
        "!pip install tensorboardX\n",
        "!pip install torch==1.7 torchvision==0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwG2aE5soays"
      },
      "source": [
        "To run experiments with approximate tensor operations, the following operations have to be compiled with a CUDA enabled GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jL6swp-zmoW"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/adelmanm/approx\n",
        "!cd approx/src/pytorch/cpp\n",
        "!python setup.py install\n",
        "!cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7h6iSLJyjeS"
      },
      "outputs": [],
      "source": [
        "# Default Python Libraries\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Required imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "import tqdm\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "\n",
        "# Torchvision\n",
        "from torchvision.datasets import CIFAR10, MNIST\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision\n",
        "\n",
        "#approx imports\n",
        "from approx_mul_pytorch import approx_Conv2d\n",
        "# tensorboard\n",
        "from tensorboardX import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "  import random, os\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(9999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtOmKV3L7fkz"
      },
      "outputs": [],
      "source": [
        "def _init_logger(optimizer):\n",
        "  d = datetime.now().strftime('%Y-%m-%d~%H:%M:%S')\n",
        "  path = f'/content/drive/MyDrive/Kappa/baseline/{optimizer}/{d}'\n",
        "\n",
        "  print(path)\n",
        "  if not os.path.exists(path + '/ckpt'):\n",
        "      os.makedirs(path + '/ckpt')\n",
        "      os.makedirs(path + '/log')\n",
        "  save_tbx_log = path + '/log'\n",
        "\n",
        "  writer = SummaryWriter(save_tbx_log)\n",
        "  return d, path, writer\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, writer):\n",
        "    model.train()\n",
        "    train_correct = 0.0\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    writer.add_scalar('Train/train_loss', running_loss / len(train_loader), epoch)\n",
        "    writer.add_scalar('Train/train_acc', (train_correct / 40000) * 100, epoch)\n",
        "        \n",
        "\n",
        "def validate(model, device, validation_loader, epoch, writer):\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in validation_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            validation_loss += F.nll_loss(output, target, reduction='sum').item() \n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    validation_loss /= len(validation_loader.dataset)\n",
        "    print('Epoch: {}, \\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) elapsed_time: {:.2f} sec\\n'.format(epoch,\n",
        "         validation_loss, correct, validation_size,\n",
        "        100. * correct / validation_size, time.time()-t_start))\n",
        "    \n",
        "    writer.add_scalar(\"Validation/Val Acc\", 100. * correct / validation_size, epoch)\n",
        "    writer.add_scalar(\"Validation/Val loss\", validation_loss, epoch)\n",
        "\n",
        "    return 100. * correct / validation_size\n",
        "    \n",
        "    \n",
        "def test(model, device, test_loader, writer):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() \n",
        "            pred = output.max(1, keepdim=True)[1] \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    writer.add_scalar('Test/Test Acc', 100. * correct / len(test_loader.dataset), 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3yvIbFGehxh",
        "outputId": "1a19484b-0bab-473e-e088-f65245cd8409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device cuda\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "use_cuda =  torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "print(\"using device \" + str(device))\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50YTc7I4H3Xs"
      },
      "outputs": [],
      "source": [
        "# cifar10\n",
        "def load_cifar10():\n",
        "  train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "  test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "  trainset = datasets.CIFAR10(root='../data', train=True,\n",
        "                                          download=True, transform=train_transform)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "  \n",
        "  testset = datasets.CIFAR10(root='../data', train=False,\n",
        "                                        download=True, transform=test_transform)\n",
        "   # Define the indices\n",
        "  indices = list(range(len(trainset)))  # start with all the indices in training set\n",
        "\n",
        "  global train_size, validation_size\n",
        "  validation_size = 10000  # define the split size\n",
        "  train_size = len(trainset) - validation_size\n",
        "  print('training set size: {} samples',train_size)\n",
        "  print('validation set size: {} samples', validation_size)\n",
        "\n",
        "  # Random, non-contiguous split\n",
        "  validation_idx = np.random.choice(indices, size=validation_size, replace=False)\n",
        "  train_idx = list(set(indices) - set(validation_idx))\n",
        "\n",
        "    # define our samplers -- we use a SubsetRandomSampler because it will return\n",
        "  # a random subset of the split defined by the given indices without replacement\n",
        "  train_sampler = SubsetRandomSampler(train_idx)\n",
        "  validation_sampler = SubsetRandomSampler(validation_idx)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      dataset = trainset,\n",
        "      batch_size=batch_size, sampler=train_sampler, **kwargs)\n",
        "  validation_loader = torch.utils.data.DataLoader(\n",
        "      dataset=trainset,\n",
        "      batch_size=batch_size, sampler=validation_sampler, **kwargs)  \n",
        "  test_loader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "  classes = ('plane', 'car', 'bird', 'cat',\n",
        "            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "  return train_loader, validation_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWkKAyJF7_PF"
      },
      "outputs": [],
      "source": [
        "### Based on https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "\n",
        "\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1, approx = False):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    if approx == True:\n",
        "      return approx_Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                      padding=dilation, groups=groups, bias=False, dilation=dilation, minimal_k=10, sample_ratio=0.5)\n",
        "    else:\n",
        "      return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                      padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1, approx = False):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    if approx == True:\n",
        "      return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "    else:\n",
        "      return approx_Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False, minimal_k=10, sample_ratio=0.5)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "        approx = False\n",
        "    ) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride, approx = approx)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes, approx = approx)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        block: Type[Union[BasicBlock]],\n",
        "        layers: List[int],\n",
        "        num_classes: int = 1000,\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "        approx = False\n",
        "    ) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], approx = False)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0], approx = False)\n",
        "        \n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1], approx = True)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2], approx = True)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                \"\"\"if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\"\"\"\n",
        "                if isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        "\n",
        "    def _make_layer(self, block: Type[Union[BasicBlock]], planes: int, blocks: int,\n",
        "                    stride: int = 1, dilate: bool = False, approx = False) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride, approx = approx),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer, approx = approx))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer, approx = approx))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _resnet(\n",
        "    arch: str,\n",
        "    block: Type[Union[BasicBlock]],\n",
        "    layers: List[int],\n",
        "    pretrained: bool,\n",
        "    progress: bool,\n",
        "    approx = False,\n",
        "    **kwargs: Any\n",
        ") -> ResNet:\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    \"\"\"if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\"\"\"\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(pretrained: bool = False, progress: bool = True, approx = False, **kwargs: Any) -> ResNet:\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, approx=approx,\n",
        "                   **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9kPofQvDygv"
      },
      "outputs": [],
      "source": [
        "best_val_acc = 0\n",
        "\n",
        "start_epoch = 1\n",
        "\n",
        "max_epoch = 40\n",
        "train_loader, validation_loader, test_loader = load_cifar10()\n",
        "\n",
        "approx = False # Toggle based on experiment\n",
        "\n",
        "optimizers = ['SGD', 'SGD_mom', 'Adam', 'Adadelta', 'RMSProp', 'Adagrad']\n",
        "for optim in optimizers:\n",
        "    dataset = 'cifar10'\n",
        "    name = optim\n",
        "    d, path, writer = _init_logger(f'{dataset}_{name}')\n",
        "    if approx == True:\n",
        "      model = resnet18(approx=True)\n",
        "    else:\n",
        "      model = torchvision.models.resnet18(False)\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "    model.maxpool = nn.Identity()\n",
        "    model.fc = nn.Sequential(nn.Linear(512, 10), nn.LogSoftmax(dim=1))\n",
        "    model.to(device)\n",
        "    print(optim)\n",
        "    \n",
        "    if optim == 'SGD':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "    elif optim == 'SGD_mom':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.99, nesterov=True)\n",
        "    if optim == 'Adam':\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "    elif optim == 'Adadelta':\n",
        "        optimizer = torch.optim.Adadelta(model.parameters(), lr=1e-2)\n",
        "    elif optim == 'Adagrad':\n",
        "        optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-2)\n",
        "    elif optim == 'RMSProp':\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-2)\n",
        "\n",
        "    global t_start\n",
        "    t_start = time.time()\n",
        "    for epoch in tqdm.notebook.tqdm(range(max_epoch)):\n",
        "        train(model, device, train_loader, optimizer, epoch, writer)\n",
        "        val_acc = validate(model, device, validation_loader, epoch, writer)\n",
        "        print(val_acc)\n",
        "        if (val_acc >= best_val_acc):\n",
        "          best_val_acc = val_acc\n",
        "          print('best_val_acc:', best_val_acc)\n",
        "          state = {\n",
        "          'epoch': epoch,\n",
        "          'best_val_acc': best_val_acc,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'optimizer': optimizer.state_dict(),\n",
        "          }\n",
        "          torch.save(state, f'{path}/ckpt/{d}.pth')\n",
        "\n",
        "    t_end = time.time()\n",
        "    print('Total training time: {:.2f} sec'.format(t_end-t_start))\n",
        "\n",
        "    model.load_state_dict(torch.load(f'{path}/ckpt/{d}.pth')['state_dict'])\n",
        "    model.eval()\n",
        "    test(model, device, test_loader, writer)\n",
        "    writer.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "Baseline_Approx_Training_Harness.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
